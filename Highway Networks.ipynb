{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Highway Networks\n",
    "\n",
    "http://people.idsia.ch/~rupesh/very_deep_learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# wget https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/examples/tutorials/mnist/input_data.py\n",
    "import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\textbf{y} = H(\\textbf{x}, \\textbf{W}_\\textbf{H}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dense_layer(x, input_size, output_size, activation):\n",
    "    W = tf.Variable(tf.truncated_normal([input_size, output_size], stddev=0.1), name='weight')\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[output_size]), name='bias')\n",
    "    y = activation(tf.matmul(x, W) + b)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "  \\textbf{y} &= H(\\textbf{x}, \\textbf{W}_\\textbf{H}) \\cdot T(\\textbf{x}, \\textbf{W}_\\textbf{T}) + \\textbf{x} \\cdot C(\\textbf{x}, \\textbf{W}_\\textbf{C}) \\\\\n",
    "  \\textbf{y} &= H(\\textbf{x}, \\textbf{W}_\\textbf{H}) \\cdot T(\\textbf{x}, \\textbf{W}_\\textbf{T}) + \\textbf{x} \\cdot (1 - T(x, \\textbf{W}_\\textbf{T}))\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def highway_layer(x, size, activation, carry_bias=-1.0):\n",
    "    W = tf.Variable(tf.truncated_normal([size, size], stddev=0.1), name='weight')\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[size]), name='bias')\n",
    "\n",
    "    W_T = tf.Variable(tf.truncated_normal([size, size], stddev=0.1), name='weight_transform')\n",
    "    b_T = tf.Variable(tf.constant(carry_bias, shape=[size]), name='bias_transform')\n",
    "\n",
    "    H = activation(tf.matmul(x, W) + b, name='activation')\n",
    "    T = tf.sigmoid(tf.matmul(x, W_T) + b_T, name='transform_gate')\n",
    "    C = tf.sub(1.0, T, name=\"carry_gate\")\n",
    "\n",
    "    y = tf.add(tf.mul(H, T), tf.mul(x, C), 'y') # y = (H * T) + (x * C)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/andy/data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/andy/data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/andy/data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/andy/data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(os.path.expanduser('~') + \"/data/mnist/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_layer_size = 784\n",
    "hidden_layer_size = 50 # use ~71 for fully-connected (plain) layers, 50 for highway layers\n",
    "output_layer_size = 10\n",
    "\n",
    "x = tf.placeholder(\"float\", [None, input_layer_size])\n",
    "y_ = tf.placeholder(\"float\", [None, output_layer_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_count = 50\n",
    "carry_bias_init = -2.0\n",
    "\n",
    "prev_y = None\n",
    "y = None\n",
    "for i in range(layer_count):\n",
    "    with tf.name_scope(\"layer{0}\".format(i)) as scope:\n",
    "        if i == 0: # first, input layer\n",
    "            prev_y = dense_layer(x, input_layer_size, hidden_layer_size, tf.nn.relu)\n",
    "        elif i == layer_count - 1: # last, output layer\n",
    "            y = dense_layer(prev_y, hidden_layer_size, output_layer_size, tf.nn.softmax)\n",
    "        else: # hidden layers\n",
    "            # prev_y = dense_layer(prev_y, hidden_layer_size, hidden_layer_size, tf.nn.relu)\n",
    "            prev_y = highway_layer(prev_y, hidden_layer_size, tf.nn.relu, carry_bias=carry_bias_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\") as scope:\n",
    "    cross_entropy = -tf.reduce_sum(y_ * tf.log(y))\n",
    "    cross_entropy_summary = tf.scalar_summary(\"loss\", cross_entropy)\n",
    "\n",
    "with tf.name_scope(\"train\") as scope:\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "with tf.name_scope(\"test\") as scope:\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    accuracy_summary = tf.scalar_summary(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_logs_1451456027/\n"
     ]
    }
   ],
   "source": [
    "merged = tf.merge_all_summaries()\n",
    "\n",
    "log_path = \"mnist_logs_{0}/\".format(int(time.time()))\n",
    "print(log_path)\n",
    "writer = tf.train.SummaryWriter(log_path, sess.graph_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 20 epochs with mini batch size of 50\n",
      "With 1100 iterations per epoch for a total of 22000 iterations\n"
     ]
    }
   ],
   "source": [
    "tf.initialize_all_variables().run()\n",
    "mini_batch_size = 50\n",
    "num_epochs = 20\n",
    "iter_per_epoch = int(mnist.train.num_examples / mini_batch_size)\n",
    "num_iter = num_epochs * iter_per_epoch\n",
    "print(\"Running %d epochs with mini batch size of %d\" % (num_epochs, mini_batch_size))\n",
    "print(\"With %d iterations per epoch for a total of %d iterations\" % (iter_per_epoch, num_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, epoch 0, training accuracy 0.1\n",
      "test accuracy 0.101\n",
      "iter 100, epoch 0, training accuracy 0.12\n",
      "test accuracy 0.098\n",
      "iter 200, epoch 0, training accuracy 0.16\n",
      "test accuracy 0.1135\n",
      "iter 300, epoch 0, training accuracy 0.06\n",
      "test accuracy 0.098\n",
      "iter 400, epoch 0, training accuracy 0.12\n",
      "test accuracy 0.1135\n",
      "iter 500, epoch 0, training accuracy 0.08\n",
      "test accuracy 0.1009\n",
      "iter 600, epoch 0, training accuracy 0.02\n",
      "test accuracy 0.1028\n",
      "iter 700, epoch 0, training accuracy 0.12\n",
      "test accuracy 0.1135\n",
      "iter 800, epoch 0, training accuracy 0.1\n",
      "test accuracy 0.1028\n",
      "iter 900, epoch 0, training accuracy 0.14\n",
      "test accuracy 0.101\n",
      "iter 1000, epoch 0, training accuracy 0.1\n",
      "test accuracy 0.101\n",
      "iter 1100, epoch 1, training accuracy 0.2\n",
      "test accuracy 0.1028\n",
      "iter 1200, epoch 1, training accuracy 0.06\n",
      "test accuracy 0.098\n",
      "iter 1300, epoch 1, training accuracy 0.06\n",
      "test accuracy 0.1135\n",
      "iter 1400, epoch 1, training accuracy 0.32\n",
      "test accuracy 0.2545\n",
      "iter 1500, epoch 1, training accuracy 0.36\n",
      "test accuracy 0.4224\n",
      "iter 1600, epoch 1, training accuracy 0.72\n",
      "test accuracy 0.6617\n",
      "iter 1700, epoch 1, training accuracy 0.74\n",
      "test accuracy 0.6958\n",
      "iter 1800, epoch 1, training accuracy 0.7\n",
      "test accuracy 0.7465\n",
      "iter 1900, epoch 1, training accuracy 0.8\n",
      "test accuracy 0.8112\n",
      "iter 2000, epoch 1, training accuracy 0.76\n",
      "test accuracy 0.7577\n",
      "iter 2100, epoch 1, training accuracy 0.86\n",
      "test accuracy 0.8839\n",
      "iter 2200, epoch 2, training accuracy 0.9\n",
      "test accuracy 0.8987\n",
      "iter 2300, epoch 2, training accuracy 0.9\n",
      "test accuracy 0.8896\n",
      "iter 2400, epoch 2, training accuracy 0.9\n",
      "test accuracy 0.7847\n",
      "iter 2500, epoch 2, training accuracy 0.92\n",
      "test accuracy 0.8987\n",
      "iter 2600, epoch 2, training accuracy 0.9\n",
      "test accuracy 0.9085\n",
      "iter 2700, epoch 2, training accuracy 0.88\n",
      "test accuracy 0.873\n",
      "iter 2800, epoch 2, training accuracy 0.92\n",
      "test accuracy 0.9131\n",
      "iter 2900, epoch 2, training accuracy 0.92\n",
      "test accuracy 0.9093\n",
      "iter 3000, epoch 2, training accuracy 0.96\n",
      "test accuracy 0.9223\n",
      "iter 3100, epoch 2, training accuracy 0.94\n",
      "test accuracy 0.9184\n",
      "iter 3200, epoch 2, training accuracy 0.98\n",
      "test accuracy 0.9231\n",
      "iter 3300, epoch 3, training accuracy 0.94\n",
      "test accuracy 0.9217\n",
      "iter 3400, epoch 3, training accuracy 0.92\n",
      "test accuracy 0.9159\n",
      "iter 3500, epoch 3, training accuracy 0.92\n",
      "test accuracy 0.9256\n",
      "iter 3600, epoch 3, training accuracy 0.9\n",
      "test accuracy 0.927\n",
      "iter 3700, epoch 3, training accuracy 0.92\n",
      "test accuracy 0.9231\n",
      "iter 3800, epoch 3, training accuracy 1\n",
      "test accuracy 0.926\n",
      "iter 3900, epoch 3, training accuracy 0.96\n",
      "test accuracy 0.9282\n",
      "iter 4000, epoch 3, training accuracy 0.92\n",
      "test accuracy 0.9347\n",
      "iter 4100, epoch 3, training accuracy 0.88\n",
      "test accuracy 0.9281\n",
      "iter 4200, epoch 3, training accuracy 0.96\n",
      "test accuracy 0.9336\n",
      "iter 4300, epoch 3, training accuracy 0.9\n",
      "test accuracy 0.9337\n",
      "iter 4400, epoch 4, training accuracy 0.92\n",
      "test accuracy 0.9319\n",
      "iter 4500, epoch 4, training accuracy 0.98\n",
      "test accuracy 0.9328\n",
      "iter 4600, epoch 4, training accuracy 0.98\n",
      "test accuracy 0.9432\n",
      "iter 4700, epoch 4, training accuracy 0.94\n",
      "test accuracy 0.9364\n",
      "iter 4800, epoch 4, training accuracy 0.96\n",
      "test accuracy 0.9399\n",
      "iter 4900, epoch 4, training accuracy 0.92\n",
      "test accuracy 0.9193\n",
      "iter 5000, epoch 4, training accuracy 0.98\n",
      "test accuracy 0.9414\n",
      "iter 5100, epoch 4, training accuracy 0.96\n",
      "test accuracy 0.9417\n",
      "iter 5200, epoch 4, training accuracy 0.94\n",
      "test accuracy 0.9435\n",
      "iter 5300, epoch 4, training accuracy 0.94\n",
      "test accuracy 0.9414\n",
      "iter 5400, epoch 4, training accuracy 0.88\n",
      "test accuracy 0.9423\n",
      "iter 5500, epoch 5, training accuracy 0.96\n",
      "test accuracy 0.9393\n",
      "iter 5600, epoch 5, training accuracy 0.92\n",
      "test accuracy 0.946\n",
      "iter 5700, epoch 5, training accuracy 0.96\n",
      "test accuracy 0.9405\n",
      "iter 5800, epoch 5, training accuracy 0.9\n",
      "test accuracy 0.9445\n",
      "iter 5900, epoch 5, training accuracy 0.98\n",
      "test accuracy 0.9449\n",
      "iter 6000, epoch 5, training accuracy 0.96\n",
      "test accuracy 0.943\n",
      "iter 6100, epoch 5, training accuracy 0.86\n",
      "test accuracy 0.9293\n",
      "iter 6200, epoch 5, training accuracy 0.96\n",
      "test accuracy 0.9439\n",
      "iter 6300, epoch 5, training accuracy 1\n",
      "test accuracy 0.9466\n",
      "iter 6400, epoch 5, training accuracy 0.96\n",
      "test accuracy 0.9399\n",
      "iter 6500, epoch 5, training accuracy 0.96\n",
      "test accuracy 0.9487\n",
      "iter 6600, epoch 6, training accuracy 0.98\n",
      "test accuracy 0.9491\n",
      "iter 6700, epoch 6, training accuracy 0.9\n",
      "test accuracy 0.9487\n",
      "iter 6800, epoch 6, training accuracy 0.92\n",
      "test accuracy 0.9442\n",
      "iter 6900, epoch 6, training accuracy 0.88\n",
      "test accuracy 0.9522\n",
      "iter 7000, epoch 6, training accuracy 1\n",
      "test accuracy 0.9435\n",
      "iter 7100, epoch 6, training accuracy 0.94\n",
      "test accuracy 0.9513\n",
      "iter 7200, epoch 6, training accuracy 0.96\n",
      "test accuracy 0.9493\n",
      "iter 7300, epoch 6, training accuracy 0.94\n",
      "test accuracy 0.9498\n",
      "iter 7400, epoch 6, training accuracy 0.96\n",
      "test accuracy 0.9451\n",
      "iter 7500, epoch 6, training accuracy 0.98\n",
      "test accuracy 0.9463\n",
      "iter 7600, epoch 6, training accuracy 0.94\n",
      "test accuracy 0.9477\n",
      "iter 7700, epoch 7, training accuracy 0.96\n",
      "test accuracy 0.9475\n",
      "iter 7800, epoch 7, training accuracy 0.96\n",
      "test accuracy 0.9547\n",
      "iter 7900, epoch 7, training accuracy 0.98\n",
      "test accuracy 0.9519\n",
      "iter 8000, epoch 7, training accuracy 0.92\n",
      "test accuracy 0.9544\n",
      "iter 8100, epoch 7, training accuracy 0.98\n",
      "test accuracy 0.9466\n",
      "iter 8200, epoch 7, training accuracy 0.96\n",
      "test accuracy 0.9507\n",
      "iter 8300, epoch 7, training accuracy 0.94\n",
      "test accuracy 0.9568\n",
      "iter 8400, epoch 7, training accuracy 0.94\n",
      "test accuracy 0.9539\n",
      "iter 8500, epoch 7, training accuracy 0.96\n",
      "test accuracy 0.9526\n",
      "iter 8600, epoch 7, training accuracy 0.96\n",
      "test accuracy 0.9503\n",
      "iter 8700, epoch 7, training accuracy 0.92\n",
      "test accuracy 0.9486\n",
      "iter 8800, epoch 8, training accuracy 0.94\n",
      "test accuracy 0.9553\n",
      "iter 8900, epoch 8, training accuracy 0.98\n",
      "test accuracy 0.9462\n",
      "iter 9000, epoch 8, training accuracy 0.96\n",
      "test accuracy 0.9534\n",
      "iter 9100, epoch 8, training accuracy 1\n",
      "test accuracy 0.9538\n",
      "iter 9200, epoch 8, training accuracy 0.94\n",
      "test accuracy 0.9536\n",
      "iter 9300, epoch 8, training accuracy 0.94\n",
      "test accuracy 0.9537\n",
      "iter 9400, epoch 8, training accuracy 1\n",
      "test accuracy 0.9517\n",
      "iter 9500, epoch 8, training accuracy 0.96\n",
      "test accuracy 0.9516\n",
      "iter 9600, epoch 8, training accuracy 0.98\n",
      "test accuracy 0.951\n",
      "iter 9700, epoch 8, training accuracy 0.92\n",
      "test accuracy 0.9534\n",
      "iter 9800, epoch 8, training accuracy 0.94\n",
      "test accuracy 0.9558\n",
      "iter 9900, epoch 9, training accuracy 0.98\n",
      "test accuracy 0.9569\n",
      "iter 10000, epoch 9, training accuracy 1\n",
      "test accuracy 0.957\n",
      "iter 10100, epoch 9, training accuracy 1\n",
      "test accuracy 0.9565\n",
      "iter 10200, epoch 9, training accuracy 0.9\n",
      "test accuracy 0.9268\n",
      "iter 10300, epoch 9, training accuracy 0.96\n",
      "test accuracy 0.9509\n",
      "iter 10400, epoch 9, training accuracy 0.96\n",
      "test accuracy 0.9547\n",
      "iter 10500, epoch 9, training accuracy 0.98\n",
      "test accuracy 0.9549\n",
      "iter 10600, epoch 9, training accuracy 0.9\n",
      "test accuracy 0.9537\n",
      "iter 10700, epoch 9, training accuracy 0.92\n",
      "test accuracy 0.9508\n",
      "iter 10800, epoch 9, training accuracy 0.98\n",
      "test accuracy 0.9555\n",
      "iter 10900, epoch 9, training accuracy 1\n",
      "test accuracy 0.9562\n",
      "iter 11000, epoch 10, training accuracy 0.98\n",
      "test accuracy 0.9544\n",
      "iter 11100, epoch 10, training accuracy 0.98\n",
      "test accuracy 0.9568\n",
      "iter 11200, epoch 10, training accuracy 0.98\n",
      "test accuracy 0.9597\n",
      "iter 11300, epoch 10, training accuracy 0.94\n",
      "test accuracy 0.9565\n",
      "iter 11400, epoch 10, training accuracy 0.98\n",
      "test accuracy 0.9541\n",
      "iter 11500, epoch 10, training accuracy 0.9\n",
      "test accuracy 0.9521\n",
      "iter 11600, epoch 10, training accuracy 1\n",
      "test accuracy 0.9549\n",
      "iter 11700, epoch 10, training accuracy 1\n",
      "test accuracy 0.9541\n",
      "iter 11800, epoch 10, training accuracy 1\n",
      "test accuracy 0.9571\n",
      "iter 11900, epoch 10, training accuracy 0.94\n",
      "test accuracy 0.9502\n",
      "iter 12000, epoch 10, training accuracy 1\n",
      "test accuracy 0.9561\n",
      "iter 12100, epoch 11, training accuracy 0.98\n",
      "test accuracy 0.9589\n",
      "iter 12200, epoch 11, training accuracy 1\n",
      "test accuracy 0.9554\n",
      "iter 12300, epoch 11, training accuracy 0.98\n",
      "test accuracy 0.9587\n",
      "iter 12400, epoch 11, training accuracy 0.96\n",
      "test accuracy 0.9522\n",
      "iter 12500, epoch 11, training accuracy 0.94\n",
      "test accuracy 0.933\n",
      "iter 12600, epoch 11, training accuracy 0.98\n",
      "test accuracy 0.9581\n",
      "iter 12700, epoch 11, training accuracy 0.94\n",
      "test accuracy 0.9548\n",
      "iter 12800, epoch 11, training accuracy 0.96\n",
      "test accuracy 0.9581\n",
      "iter 12900, epoch 11, training accuracy 0.98\n",
      "test accuracy 0.9563\n",
      "iter 13000, epoch 11, training accuracy 0.96\n",
      "test accuracy 0.9549\n",
      "iter 13100, epoch 11, training accuracy 0.98\n",
      "test accuracy 0.9561\n",
      "iter 13200, epoch 12, training accuracy 0.96\n",
      "test accuracy 0.9596\n",
      "iter 13300, epoch 12, training accuracy 1\n",
      "test accuracy 0.9571\n",
      "iter 13400, epoch 12, training accuracy 0.98\n",
      "test accuracy 0.9597\n",
      "iter 13500, epoch 12, training accuracy 1\n",
      "test accuracy 0.9577\n",
      "iter 13600, epoch 12, training accuracy 1\n",
      "test accuracy 0.961\n",
      "iter 13700, epoch 12, training accuracy 0.96\n",
      "test accuracy 0.9559\n",
      "iter 13800, epoch 12, training accuracy 0.96\n",
      "test accuracy 0.9577\n",
      "iter 13900, epoch 12, training accuracy 0.98\n",
      "test accuracy 0.9602\n",
      "iter 14000, epoch 12, training accuracy 1\n",
      "test accuracy 0.9585\n",
      "iter 14100, epoch 12, training accuracy 1\n",
      "test accuracy 0.9577\n",
      "iter 14200, epoch 12, training accuracy 0.98\n",
      "test accuracy 0.9545\n",
      "iter 14300, epoch 13, training accuracy 0.96\n",
      "test accuracy 0.9589\n",
      "iter 14400, epoch 13, training accuracy 0.94\n",
      "test accuracy 0.9592\n",
      "iter 14500, epoch 13, training accuracy 0.98\n",
      "test accuracy 0.9577\n",
      "iter 14600, epoch 13, training accuracy 0.96\n",
      "test accuracy 0.9613\n",
      "iter 14700, epoch 13, training accuracy 0.98\n",
      "test accuracy 0.9576\n",
      "iter 14800, epoch 13, training accuracy 0.98\n",
      "test accuracy 0.9598\n",
      "iter 14900, epoch 13, training accuracy 0.98\n",
      "test accuracy 0.9508\n",
      "iter 15000, epoch 13, training accuracy 1\n",
      "test accuracy 0.9602\n",
      "iter 15100, epoch 13, training accuracy 0.98\n",
      "test accuracy 0.9586\n",
      "iter 15200, epoch 13, training accuracy 0.94\n",
      "test accuracy 0.9602\n",
      "iter 15300, epoch 13, training accuracy 0.94\n",
      "test accuracy 0.9567\n",
      "iter 15400, epoch 14, training accuracy 1\n",
      "test accuracy 0.9582\n",
      "iter 15500, epoch 14, training accuracy 0.94\n",
      "test accuracy 0.958\n",
      "iter 15600, epoch 14, training accuracy 1\n",
      "test accuracy 0.9598\n",
      "iter 15700, epoch 14, training accuracy 1\n",
      "test accuracy 0.961\n",
      "iter 15800, epoch 14, training accuracy 0.96\n",
      "test accuracy 0.9473\n",
      "iter 15900, epoch 14, training accuracy 1\n",
      "test accuracy 0.9565\n",
      "iter 16000, epoch 14, training accuracy 0.96\n",
      "test accuracy 0.9548\n",
      "iter 16100, epoch 14, training accuracy 0.9\n",
      "test accuracy 0.9565\n",
      "iter 16200, epoch 14, training accuracy 0.96\n",
      "test accuracy 0.9598\n",
      "iter 16300, epoch 14, training accuracy 0.96\n",
      "test accuracy 0.9554\n",
      "iter 16400, epoch 14, training accuracy 1\n",
      "test accuracy 0.9612\n",
      "iter 16500, epoch 15, training accuracy 1\n",
      "test accuracy 0.9615\n",
      "iter 16600, epoch 15, training accuracy 0.98\n",
      "test accuracy 0.9612\n",
      "iter 16700, epoch 15, training accuracy 1\n",
      "test accuracy 0.9567\n",
      "iter 16800, epoch 15, training accuracy 0.96\n",
      "test accuracy 0.962\n",
      "iter 16900, epoch 15, training accuracy 0.98\n",
      "test accuracy 0.9519\n",
      "iter 17000, epoch 15, training accuracy 1\n",
      "test accuracy 0.9523\n",
      "iter 17100, epoch 15, training accuracy 0.94\n",
      "test accuracy 0.9621\n",
      "iter 17200, epoch 15, training accuracy 1\n",
      "test accuracy 0.9638\n",
      "iter 17300, epoch 15, training accuracy 0.98\n",
      "test accuracy 0.9599\n",
      "iter 17400, epoch 15, training accuracy 1\n",
      "test accuracy 0.9571\n",
      "iter 17500, epoch 15, training accuracy 0.98\n",
      "test accuracy 0.9628\n",
      "iter 17600, epoch 16, training accuracy 1\n",
      "test accuracy 0.9601\n",
      "iter 17700, epoch 16, training accuracy 1\n",
      "test accuracy 0.9565\n",
      "iter 17800, epoch 16, training accuracy 0.98\n",
      "test accuracy 0.96\n",
      "iter 17900, epoch 16, training accuracy 0.96\n",
      "test accuracy 0.958\n",
      "iter 18000, epoch 16, training accuracy 0.92\n",
      "test accuracy 0.945\n",
      "iter 18100, epoch 16, training accuracy 0.94\n",
      "test accuracy 0.9586\n",
      "iter 18200, epoch 16, training accuracy 0.98\n",
      "test accuracy 0.9629\n",
      "iter 18300, epoch 16, training accuracy 1\n",
      "test accuracy 0.9623\n",
      "iter 18400, epoch 16, training accuracy 0.98\n",
      "test accuracy 0.9649\n",
      "iter 18500, epoch 16, training accuracy 0.98\n",
      "test accuracy 0.9639\n",
      "iter 18600, epoch 16, training accuracy 0.98\n",
      "test accuracy 0.9609\n",
      "iter 18700, epoch 17, training accuracy 0.96\n",
      "test accuracy 0.96\n",
      "iter 18800, epoch 17, training accuracy 0.98\n",
      "test accuracy 0.9592\n",
      "iter 18900, epoch 17, training accuracy 0.98\n",
      "test accuracy 0.9613\n",
      "iter 19000, epoch 17, training accuracy 0.94\n",
      "test accuracy 0.961\n",
      "iter 19100, epoch 17, training accuracy 0.98\n",
      "test accuracy 0.9619\n",
      "iter 19200, epoch 17, training accuracy 1\n",
      "test accuracy 0.9614\n",
      "iter 19300, epoch 17, training accuracy 1\n",
      "test accuracy 0.9629\n",
      "iter 19400, epoch 17, training accuracy 0.98\n",
      "test accuracy 0.9545\n",
      "iter 19500, epoch 17, training accuracy 1\n",
      "test accuracy 0.9622\n",
      "iter 19600, epoch 17, training accuracy 0.98\n",
      "test accuracy 0.964\n",
      "iter 19700, epoch 17, training accuracy 0.98\n",
      "test accuracy 0.9583\n",
      "iter 19800, epoch 18, training accuracy 0.98\n",
      "test accuracy 0.9602\n",
      "iter 19900, epoch 18, training accuracy 0.94\n",
      "test accuracy 0.9634\n",
      "iter 20000, epoch 18, training accuracy 1\n",
      "test accuracy 0.9622\n",
      "iter 20100, epoch 18, training accuracy 0.98\n",
      "test accuracy 0.9624\n",
      "iter 20200, epoch 18, training accuracy 0.98\n",
      "test accuracy 0.96\n",
      "iter 20300, epoch 18, training accuracy 0.94\n",
      "test accuracy 0.9632\n",
      "iter 20400, epoch 18, training accuracy 0.98\n",
      "test accuracy 0.9548\n",
      "iter 20500, epoch 18, training accuracy 0.98\n",
      "test accuracy 0.9597\n",
      "iter 20600, epoch 18, training accuracy 0.98\n",
      "test accuracy 0.9598\n",
      "iter 20700, epoch 18, training accuracy 0.98\n",
      "test accuracy 0.9602\n",
      "iter 20800, epoch 18, training accuracy 1\n",
      "test accuracy 0.9606\n",
      "iter 20900, epoch 19, training accuracy 0.98\n",
      "test accuracy 0.9552\n",
      "iter 21000, epoch 19, training accuracy 0.98\n",
      "test accuracy 0.9626\n",
      "iter 21100, epoch 19, training accuracy 1\n",
      "test accuracy 0.9593\n",
      "iter 21200, epoch 19, training accuracy 1\n",
      "test accuracy 0.9608\n",
      "iter 21300, epoch 19, training accuracy 0.94\n",
      "test accuracy 0.9586\n",
      "iter 21400, epoch 19, training accuracy 0.96\n",
      "test accuracy 0.9636\n",
      "iter 21500, epoch 19, training accuracy 0.9\n",
      "test accuracy 0.9608\n",
      "iter 21600, epoch 19, training accuracy 0.96\n",
      "test accuracy 0.9656\n",
      "iter 21700, epoch 19, training accuracy 0.98\n",
      "test accuracy 0.9605\n",
      "iter 21800, epoch 19, training accuracy 1\n",
      "test accuracy 0.9616\n",
      "iter 21900, epoch 19, training accuracy 0.98\n",
      "test accuracy 0.9438\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_iter):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(50)\n",
    "\n",
    "  if i % 100 == 0:\n",
    "    summary_str, train_accuracy = sess.run([merged, accuracy], feed_dict={\n",
    "        x: batch_xs,\n",
    "        y_: batch_ys,\n",
    "    })\n",
    "    writer.add_summary(summary_str, i)\n",
    "    print(\"iter %d, epoch %d, training accuracy %g\" % (i, i / iter_per_epoch, train_accuracy))\n",
    "    print(\"test accuracy %g\" % accuracy.eval(feed_dict={ x: mnist.test.images, y_: mnist.test.labels }))\n",
    "\n",
    "  train_step.run(feed_dict={ x: batch_xs, y_: batch_ys })\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
