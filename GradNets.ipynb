{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradNets\n",
    "\n",
    "http://arxiv.org/pdf/1511.06827v1.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# wget https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/examples/tutorials/mnist/input_data.py\n",
    "import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "g = min(t/\\tau, 1)\n",
    "$$\n",
    "\n",
    "Where $g \\in (0, 1)$ and $t$ is the current epoch. In code, `g` is a weight that anneals over $\\tau$ epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dense_layer(x, input_size, output_size, activation):\n",
    "    W = tf.Variable(tf.truncated_normal([input_size, output_size], stddev=0.1), name='weight')\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[output_size]), name='bias')\n",
    "    y = activation(tf.matmul(x, W) + b)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grelu_layer(x, input_size, output_size, g):\n",
    "    W = tf.Variable(tf.truncated_normal([input_size, output_size], stddev=0.1), name='weight')\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[output_size]), name='bias')\n",
    "    y = g * tf.nn.relu(tf.matmul(x, W) + b) + (1 - g) * x\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/andy/data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/andy/data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/andy/data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/andy/data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(os.path.expanduser('~') + \"/data/mnist/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_layer_size = 784\n",
    "hidden_layer_size = 50 # use ~71 for fully-connected (plain) layers, 50 for highway layers\n",
    "output_layer_size = 10\n",
    "\n",
    "x = tf.placeholder(\"float\", [None, input_layer_size])\n",
    "y_ = tf.placeholder(\"float\", [None, output_layer_size])\n",
    "g = tf.placeholder(\"float\")\n",
    "learning_rate = tf.placeholder(\"float\")\n",
    "mini_batch_size = 50\n",
    "num_epochs = 20\n",
    "tau = 10 # num epochs to anneal g over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_count = 50\n",
    "\n",
    "prev_y = None\n",
    "y = None\n",
    "for i in range(layer_count):\n",
    "    with tf.name_scope(\"layer{0}\".format(i)) as scope:\n",
    "        if i == 0: # first, input layer\n",
    "            prev_y = dense_layer(x, input_layer_size, hidden_layer_size, tf.nn.relu)\n",
    "        elif i == layer_count - 1: # last, output layer\n",
    "            y = dense_layer(prev_y, hidden_layer_size, output_layer_size, tf.nn.softmax)\n",
    "        else: # hidden layers\n",
    "            prev_y = grelu_layer(prev_y, hidden_layer_size, hidden_layer_size, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\") as scope:\n",
    "    cross_entropy = -tf.reduce_sum(y_ * tf.log(y))\n",
    "    cross_entropy_summary = tf.scalar_summary(\"loss\", cross_entropy)\n",
    "\n",
    "with tf.name_scope(\"train\") as scope:\n",
    "    train_step = tf.train.AdamOptimizer().minimize(cross_entropy)\n",
    "\n",
    "with tf.name_scope(\"test\") as scope:\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    accuracy_summary = tf.scalar_summary(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_logs_1451475190/\n"
     ]
    }
   ],
   "source": [
    "merged = tf.merge_all_summaries()\n",
    "\n",
    "log_path = \"mnist_logs_{0}/\".format(int(time.time()))\n",
    "print(log_path)\n",
    "writer = tf.train.SummaryWriter(log_path, sess.graph_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 20 epochs with mini batch size of 50\n",
      "With 1100 iterations per epoch for a total of 22000 iterations\n"
     ]
    }
   ],
   "source": [
    "tf.initialize_all_variables().run()\n",
    "\n",
    "iter_per_epoch = int(mnist.train.num_examples / mini_batch_size)\n",
    "num_iter = num_epochs * iter_per_epoch\n",
    "print(\"Running %d epochs with mini batch size of %d\" % (num_epochs, mini_batch_size))\n",
    "print(\"With %d iterations per epoch for a total of %d iterations\" % (iter_per_epoch, num_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, epoch 0, training accuracy 0.14, g: 0\n",
      "test accuracy 0.0645\n",
      "iter 100, epoch 0, training accuracy 0.82, g: 0.00909091\n",
      "test accuracy 0.8077\n",
      "iter 200, epoch 0, training accuracy 0.88, g: 0.0181818\n",
      "test accuracy 0.8606\n",
      "iter 300, epoch 0, training accuracy 0.8, g: 0.0272727\n",
      "test accuracy 0.8879\n",
      "iter 400, epoch 0, training accuracy 0.94, g: 0.0363636\n",
      "test accuracy 0.8931\n",
      "iter 500, epoch 0, training accuracy 0.84, g: 0.0454545\n",
      "test accuracy 0.8792\n",
      "iter 600, epoch 0, training accuracy 0.98, g: 0.0545455\n",
      "test accuracy 0.8983\n",
      "iter 700, epoch 0, training accuracy 0.88, g: 0.0636364\n",
      "test accuracy 0.9058\n",
      "iter 800, epoch 0, training accuracy 0.82, g: 0.0727273\n",
      "test accuracy 0.9072\n",
      "iter 900, epoch 0, training accuracy 0.84, g: 0.0818182\n",
      "test accuracy 0.9144\n",
      "iter 1000, epoch 0, training accuracy 0.9, g: 0.0909091\n",
      "test accuracy 0.9243\n",
      "iter 1100, epoch 1, training accuracy 0.84, g: 0.1\n",
      "test accuracy 0.909\n",
      "iter 1200, epoch 1, training accuracy 0.92, g: 0.109091\n",
      "test accuracy 0.9325\n",
      "iter 1300, epoch 1, training accuracy 0.96, g: 0.118182\n",
      "test accuracy 0.932\n",
      "iter 1400, epoch 1, training accuracy 0.94, g: 0.127273\n",
      "test accuracy 0.9335\n",
      "iter 1500, epoch 1, training accuracy 0.98, g: 0.136364\n",
      "test accuracy 0.9369\n",
      "iter 1600, epoch 1, training accuracy 0.96, g: 0.145455\n",
      "test accuracy 0.9418\n",
      "iter 1700, epoch 1, training accuracy 0.9, g: 0.154545\n",
      "test accuracy 0.9459"
     ]
    }
   ],
   "source": [
    "for i in range(num_iter):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(mini_batch_size)\n",
    "\n",
    "  epoch = i / iter_per_epoch\n",
    "  gs = min(epoch / tau, 1.0)\n",
    "\n",
    "  if i % 100 == 0:\n",
    "    summary_str, train_accuracy = sess.run([merged, accuracy], feed_dict={\n",
    "        x: batch_xs,\n",
    "        y_: batch_ys,\n",
    "        g: gs,\n",
    "    })\n",
    "    writer.add_summary(summary_str, i)\n",
    "    print(\"iter %d, epoch %d, training accuracy %g, g: %g\" % (i, epoch, train_accuracy, gs))\n",
    "    print(\"test accuracy %g\" % accuracy.eval(feed_dict={ x: mnist.test.images, y_: mnist.test.labels, g: gs }))\n",
    "\n",
    "  train_step.run(feed_dict={ x: batch_xs, y_: batch_ys, g: gs})\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
