{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradNets\n",
    "\n",
    "http://arxiv.org/pdf/1511.06827v1.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# wget https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/examples/tutorials/mnist/input_data.py\n",
    "import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dense_layer(x, input_size, output_size, activation):\n",
    "    W = tf.Variable(tf.truncated_normal([input_size, output_size], stddev=0.1), name='weight')\n",
    "    b = tf.Variable(tf.constant(0., shape=[output_size]), name='bias')\n",
    "    y = activation(tf.matmul(x, W) + b)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y = g \\cdot H(x) + (1 - g) \\cdot I(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grelu_layer(x, input_size, output_size, g):\n",
    "    W = tf.Variable(tf.truncated_normal([input_size, output_size], stddev=0.1), name='weight')\n",
    "    b = tf.Variable(tf.constant(0., shape=[output_size]), name='bias')\n",
    "    y = g * tf.nn.relu(tf.matmul(x, W) + b) + \\\n",
    "        (1 - g) * x\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/andy/data/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/andy/data/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/andy/data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/andy/data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(os.path.expanduser('~') + \"/data/mnist/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_layer_size = 784\n",
    "hidden_layer_size = 50 # use ~71 for fully-connected (plain) layers, 50 for highway layers\n",
    "output_layer_size = 10\n",
    "\n",
    "x = tf.placeholder(\"float\", [None, input_layer_size])\n",
    "y_ = tf.placeholder(\"float\", [None, output_layer_size])\n",
    "g = tf.placeholder(\"float\")\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "mini_batch_size = 50\n",
    "num_epochs = 20\n",
    "tau = 10 # num epochs to anneal g over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creates a variable to hold the global_step.\n",
    "global_step = tf.Variable(10, trainable=False, name='global_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_count = 50\n",
    "\n",
    "prev_y = None\n",
    "y = None\n",
    "for i in range(layer_count):\n",
    "    with tf.name_scope(\"layer{0}\".format(i)) as scope:\n",
    "        if i == 0: # first, input layer\n",
    "            prev_y = tf.nn.dropout(dense_layer(x, input_layer_size, hidden_layer_size, tf.nn.relu), keep_prob)\n",
    "        elif i == layer_count - 1: # last, output layer\n",
    "            y = dense_layer(prev_y, hidden_layer_size, output_layer_size, tf.nn.softmax)\n",
    "        else: # hidden layers\n",
    "            prev_y = tf.nn.dropout(grelu_layer(prev_y, hidden_layer_size, hidden_layer_size, g), keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\") as scope:\n",
    "    cross_entropy = -tf.reduce_sum(y_ * tf.log(y + 1e-9))\n",
    "    cross_entropy_summary = tf.scalar_summary(\"loss\", cross_entropy)\n",
    "\n",
    "with tf.name_scope(\"train\") as scope:\n",
    "    learning_rate = tf.train.exponential_decay(1e-3, global_step, 1000, 0.8)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    weight_gradients = [\n",
    "        (grad, var)\n",
    "        for grad, var \n",
    "        in optimizer.compute_gradients(cross_entropy) \n",
    "        if \"weight\" in var.name\n",
    "    ][1:-1] # drop layer0 and layer49\n",
    "    weights = [var for grad, var in weight_gradients]\n",
    "    grads = [grad for grad, var in weight_gradients]\n",
    "    weight_norm = tf.reduce_mean(tf.abs(tf.concat(0, weights)))\n",
    "    weight_summary = tf.scalar_summary(\"weight_norm\", weight_norm)\n",
    "    gradient_norm = tf.reduce_mean(tf.abs(tf.concat(0, grads)))\n",
    "    gradient_summary = tf.scalar_summary(\"gradient_norm\", gradient_norm)\n",
    "\n",
    "    train_step = optimizer.minimize(cross_entropy + 50 * weight_norm, global_step=global_step)\n",
    "\n",
    "with tf.name_scope(\"test\") as scope:\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    accuracy_summary = tf.scalar_summary(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_logs_1451550074/\n"
     ]
    }
   ],
   "source": [
    "merged = tf.merge_all_summaries()\n",
    "\n",
    "log_path = \"mnist_logs_{0}/\".format(int(time.time()))\n",
    "print(log_path)\n",
    "writer = tf.train.SummaryWriter(log_path, sess.graph_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 20 epochs with mini batch size of 50\n",
      "With 1100 iterations per epoch for a total of 22000 iterations\n"
     ]
    }
   ],
   "source": [
    "tf.initialize_all_variables().run()\n",
    "\n",
    "iter_per_epoch = int(mnist.train.num_examples / mini_batch_size)\n",
    "num_iter = num_epochs * iter_per_epoch\n",
    "print(\"Running %d epochs with mini batch size of %d\" % (num_epochs, mini_batch_size))\n",
    "print(\"With %d iterations per epoch for a total of %d iterations\" % (iter_per_epoch, num_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "g = min(t/\\tau, 1)\n",
    "$$\n",
    "\n",
    "Where $g \\in (0, 1)$ and $t$ is the current epoch. In code, `g` is a weight that anneals over $\\tau$ epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, epoch 0, training accuracy 0.08, g: 0\n",
      "weight norm: 0.0724656, grad norm: 0\n",
      "test accuracy 0.0931\n",
      "iter 100, epoch 0, training accuracy 0.52, g: 0.00909091\n",
      "weight norm: 0.0269349, grad norm: 0.000760927\n",
      "test accuracy 0.587\n",
      "iter 200, epoch 0, training accuracy 0.72, g: 0.0181818\n",
      "weight norm: 0.0280573, grad norm: 0.00303799\n",
      "test accuracy 0.6761\n",
      "iter 300, epoch 0, training accuracy 0.72, g: 0.0272727\n",
      "weight norm: 0.0468031, grad norm: 0.00763341\n",
      "test accuracy 0.7225\n",
      "iter 400, epoch 0, training accuracy 0.82, g: 0.0363636\n",
      "weight norm: 0.0602556, grad norm: 0.00669258\n",
      "test accuracy 0.7521\n",
      "iter 500, epoch 0, training accuracy 0.66, g: 0.0454545\n",
      "weight norm: 0.0675551, grad norm: 0.00844835\n",
      "test accuracy 0.799\n",
      "iter 600, epoch 0, training accuracy 0.94, g: 0.0545455\n",
      "weight norm: 0.0721122, grad norm: 0.0108451\n",
      "test accuracy 0.8313\n",
      "iter 700, epoch 0, training accuracy 0.9, g: 0.0636364\n",
      "weight norm: 0.0738767, grad norm: 0.00968969\n",
      "test accuracy 0.8506\n",
      "iter 800, epoch 0, training accuracy 0.88, g: 0.0727273\n",
      "weight norm: 0.0757471, grad norm: 0.0133176\n",
      "test accuracy 0.8569\n",
      "iter 900, epoch 0, training accuracy 0.82, g: 0.0818182\n",
      "weight norm: 0.0763579, grad norm: 0.0221682\n",
      "test accuracy 0.8704\n",
      "iter 1000, epoch 0, training accuracy 0.9, g: 0.0909091\n",
      "weight norm: 0.0771251, grad norm: 0.0141538\n",
      "test accuracy 0.8796\n",
      "iter 1100, epoch 1, training accuracy 0.84, g: 0.1\n",
      "weight norm: 0.0779021, grad norm: 0.0292392\n",
      "test accuracy 0.89\n",
      "iter 1200, epoch 1, training accuracy 0.94, g: 0.109091\n",
      "weight norm: 0.0779804, grad norm: 0.0168548\n",
      "test accuracy 0.8981\n",
      "iter 1300, epoch 1, training accuracy 0.84, g: 0.118182\n",
      "weight norm: 0.0782952, grad norm: 0.0224889\n",
      "test accuracy 0.9069\n",
      "iter 1400, epoch 1, training accuracy 0.94, g: 0.127273\n",
      "weight norm: 0.0782798, grad norm: 0.0120595\n",
      "test accuracy 0.9016\n",
      "iter 1500, epoch 1, training accuracy 0.9, g: 0.136364\n",
      "weight norm: 0.0782132, grad norm: 0.0180348\n",
      "test accuracy 0.9124\n",
      "iter 1600, epoch 1, training accuracy 0.94, g: 0.145455\n",
      "weight norm: 0.0783682, grad norm: 0.0159601\n",
      "test accuracy 0.9173\n",
      "iter 1700, epoch 1, training accuracy 0.92, g: 0.154545\n",
      "weight norm: 0.0782224, grad norm: 0.0167513\n",
      "test accuracy 0.9164\n",
      "iter 1800, epoch 1, training accuracy 0.94, g: 0.163636\n",
      "weight norm: 0.0776869, grad norm: 0.0147238\n",
      "test accuracy 0.9204\n",
      "iter 1900, epoch 1, training accuracy 0.92, g: 0.172727\n",
      "weight norm: 0.0775516, grad norm: 0.018506\n",
      "test accuracy 0.9168\n",
      "iter 2000, epoch 1, training accuracy 0.96, g: 0.181818\n",
      "weight norm: 0.0769031, grad norm: 0.0102797\n",
      "test accuracy 0.913\n",
      "iter 2100, epoch 1, training accuracy 0.94, g: 0.190909\n",
      "weight norm: 0.077035, grad norm: 0.0121272\n",
      "test accuracy 0.9224\n",
      "iter 2200, epoch 2, training accuracy 0.98, g: 0.2\n",
      "weight norm: 0.0767644, grad norm: 0.00893504\n",
      "test accuracy 0.9235\n",
      "iter 2300, epoch 2, training accuracy 0.94, g: 0.209091\n",
      "weight norm: 0.0764647, grad norm: 0.0108289\n",
      "test accuracy 0.9209\n",
      "iter 2400, epoch 2, training accuracy 0.9, g: 0.218182\n",
      "weight norm: 0.0765359, grad norm: 0.0148167\n",
      "test accuracy 0.926\n",
      "iter 2500, epoch 2, training accuracy 0.82, g: 0.227273\n",
      "weight norm: 0.0758947, grad norm: 0.0207501\n",
      "test accuracy 0.868\n",
      "iter 2600, epoch 2, training accuracy 0.96, g: 0.236364\n",
      "weight norm: 0.0760051, grad norm: 0.00852088\n",
      "test accuracy 0.9236\n",
      "iter 2700, epoch 2, training accuracy 0.98, g: 0.245455\n",
      "weight norm: 0.0755407, grad norm: 0.0339469\n",
      "test accuracy 0.9148\n",
      "iter 2800, epoch 2, training accuracy 0.92, g: 0.254545\n",
      "weight norm: 0.0753281, grad norm: 0.0456545\n",
      "test accuracy 0.9126\n",
      "iter 2900, epoch 2, training accuracy 0.94, g: 0.263636\n",
      "weight norm: 0.0750879, grad norm: 0.0178261\n",
      "test accuracy 0.9164\n",
      "iter 3000, epoch 2, training accuracy 0.94, g: 0.272727\n",
      "weight norm: 0.074839, grad norm: 0.0135726\n",
      "test accuracy 0.9167\n",
      "iter 3100, epoch 2, training accuracy 0.94, g: 0.281818\n",
      "weight norm: 0.0747809, grad norm: 0.039546\n",
      "test accuracy 0.9263\n",
      "iter 3200, epoch 2, training accuracy 0.92, g: 0.290909\n",
      "weight norm: 0.0744388, grad norm: 0.0232872\n",
      "test accuracy 0.9253\n",
      "iter 3300, epoch 3, training accuracy 0.9, g: 0.3\n",
      "weight norm: 0.0741872, grad norm: 0.0293687\n",
      "test accuracy 0.9057\n",
      "iter 3400, epoch 3, training accuracy 0.92, g: 0.309091\n",
      "weight norm: 0.0740483, grad norm: 0.0186198\n",
      "test accuracy 0.9189\n",
      "iter 3500, epoch 3, training accuracy 0.94, g: 0.318182\n",
      "weight norm: 0.0738003, grad norm: 0.0437086\n",
      "test accuracy 0.9309\n",
      "iter 3600, epoch 3, training accuracy 0.96, g: 0.327273\n",
      "weight norm: 0.0735833, grad norm: 0.012049\n",
      "test accuracy 0.9001\n",
      "iter 3700, epoch 3, training accuracy 0.92, g: 0.336364\n",
      "weight norm: 0.0735233, grad norm: 0.0258574\n",
      "test accuracy 0.9267\n",
      "iter 3800, epoch 3, training accuracy 0.94, g: 0.345455\n",
      "weight norm: 0.0732101, grad norm: 0.0205726\n",
      "test accuracy 0.9223\n",
      "iter 3900, epoch 3, training accuracy 0.9, g: 0.354545\n",
      "weight norm: 0.0728522, grad norm: 0.0136106\n",
      "test accuracy 0.9241\n",
      "iter 4000, epoch 3, training accuracy 0.98, g: 0.363636\n",
      "weight norm: 0.0727251, grad norm: 0.0129302\n",
      "test accuracy 0.9247\n",
      "iter 4100, epoch 3, training accuracy 0.9, g: 0.372727\n",
      "weight norm: 0.0726045, grad norm: 0.0174512\n",
      "test accuracy 0.9298\n",
      "iter 4200, epoch 3, training accuracy 0.96, g: 0.381818\n",
      "weight norm: 0.0723947, grad norm: 0.0216394\n",
      "test accuracy 0.9241\n",
      "iter 4300, epoch 3, training accuracy 0.98, g: 0.390909\n",
      "weight norm: 0.0723445, grad norm: 0.0169004\n",
      "test accuracy 0.9256\n",
      "iter 4400, epoch 4, training accuracy 0.92, g: 0.4\n",
      "weight norm: 0.0721382, grad norm: 0.0207017\n",
      "test accuracy 0.9285\n",
      "iter 4500, epoch 4, training accuracy 0.92, g: 0.409091\n",
      "weight norm: 0.0720131, grad norm: 0.0368719\n",
      "test accuracy 0.9296\n",
      "iter 4600, epoch 4, training accuracy 0.96, g: 0.418182\n",
      "weight norm: 0.0718284, grad norm: 0.0147389\n",
      "test accuracy 0.9344\n",
      "iter 4700, epoch 4, training accuracy 0.94, g: 0.427273\n",
      "weight norm: 0.0715414, grad norm: 0.0129285\n",
      "test accuracy 0.9299\n",
      "iter 4800, epoch 4, training accuracy 0.96, g: 0.436364\n",
      "weight norm: 0.0714272, grad norm: 0.0155704\n",
      "test accuracy 0.934\n",
      "iter 4900, epoch 4, training accuracy 0.94, g: 0.445455\n",
      "weight norm: 0.0712648, grad norm: 0.0202484\n",
      "test accuracy 0.9334\n",
      "iter 5000, epoch 4, training accuracy 0.96, g: 0.454545\n",
      "weight norm: 0.07116, grad norm: 0.0200173\n",
      "test accuracy 0.9285\n",
      "iter 5100, epoch 4, training accuracy 0.88, g: 0.463636\n",
      "weight norm: 0.0709094, grad norm: 0.0686939\n",
      "test accuracy 0.9305\n",
      "iter 5200, epoch 4, training accuracy 0.96, g: 0.472727\n",
      "weight norm: 0.070681, grad norm: 0.0207404\n",
      "test accuracy 0.9243\n",
      "iter 5300, epoch 4, training accuracy 0.96, g: 0.481818\n",
      "weight norm: 0.0706169, grad norm: 0.0150205\n",
      "test accuracy 0.9292\n",
      "iter 5400, epoch 4, training accuracy 0.94, g: 0.490909\n",
      "weight norm: 0.0702283, grad norm: 0.0207106\n",
      "test accuracy 0.9292\n",
      "iter 5500, epoch 5, training accuracy 0.92, g: 0.5\n",
      "weight norm: 0.0702861, grad norm: 0.0530924\n",
      "test accuracy 0.9303\n",
      "iter 5600, epoch 5, training accuracy 0.9, g: 0.509091\n",
      "weight norm: 0.0701875, grad norm: 0.0334831\n",
      "test accuracy 0.9256\n",
      "iter 5700, epoch 5, training accuracy 0.9, g: 0.518182\n",
      "weight norm: 0.0699374, grad norm: 0.0260202\n",
      "test accuracy 0.9308\n",
      "iter 5800, epoch 5, training accuracy 0.86, g: 0.527273\n",
      "weight norm: 0.0699478, grad norm: 0.0404731\n",
      "test accuracy 0.8728\n",
      "iter 5900, epoch 5, training accuracy 0.98, g: 0.536364\n",
      "weight norm: 0.0698638, grad norm: 0.0150666\n",
      "test accuracy 0.9234\n",
      "iter 6000, epoch 5, training accuracy 0.92, g: 0.545455\n",
      "weight norm: 0.0697344, grad norm: 0.0195748\n",
      "test accuracy 0.9357\n",
      "iter 6100, epoch 5, training accuracy 0.96, g: 0.554545\n",
      "weight norm: 0.0696037, grad norm: 0.0413011\n",
      "test accuracy 0.9358\n",
      "iter 6200, epoch 5, training accuracy 0.94, g: 0.563636\n",
      "weight norm: 0.0694424, grad norm: 0.0466616\n",
      "test accuracy 0.9372\n",
      "iter 6300, epoch 5, training accuracy 0.94, g: 0.572727\n",
      "weight norm: 0.0695207, grad norm: 0.021943\n",
      "test accuracy 0.9342\n",
      "iter 6400, epoch 5, training accuracy 0.94, g: 0.581818\n",
      "weight norm: 0.0693068, grad norm: 0.0281835\n",
      "test accuracy 0.9244\n",
      "iter 6500, epoch 5, training accuracy 0.92, g: 0.590909\n",
      "weight norm: 0.0692493, grad norm: 0.0321356\n",
      "test accuracy 0.9319\n",
      "iter 6600, epoch 6, training accuracy 0.9, g: 0.6\n",
      "weight norm: 0.0692053, grad norm: 0.0198063\n",
      "test accuracy 0.9265\n",
      "iter 6700, epoch 6, training accuracy 0.96, g: 0.609091\n",
      "weight norm: 0.0690465, grad norm: 0.0214807\n",
      "test accuracy 0.9295\n",
      "iter 6800, epoch 6, training accuracy 0.98, g: 0.618182\n",
      "weight norm: 0.0689652, grad norm: 0.0186208\n",
      "test accuracy 0.9146\n",
      "iter 6900, epoch 6, training accuracy 0.98, g: 0.627273\n",
      "weight norm: 0.0688836, grad norm: 0.0156541\n",
      "test accuracy 0.9235\n",
      "iter 7000, epoch 6, training accuracy 0.88, g: 0.636364\n",
      "weight norm: 0.0687198, grad norm: 0.0229457\n",
      "test accuracy 0.9314\n",
      "iter 7100, epoch 6, training accuracy 0.82, g: 0.645455\n",
      "weight norm: 0.0686327, grad norm: 0.0713256\n",
      "test accuracy 0.9357\n",
      "iter 7200, epoch 6, training accuracy 0.9, g: 0.654545\n",
      "weight norm: 0.0685546, grad norm: 0.0616211\n",
      "test accuracy 0.9357\n",
      "iter 7300, epoch 6, training accuracy 0.96, g: 0.663636\n",
      "weight norm: 0.0684725, grad norm: 0.0148702\n",
      "test accuracy 0.936\n",
      "iter 7400, epoch 6, training accuracy 0.94, g: 0.672727\n",
      "weight norm: 0.0683872, grad norm: 0.116587\n",
      "test accuracy 0.9363\n",
      "iter 7500, epoch 6, training accuracy 1, g: 0.681818\n",
      "weight norm: 0.0683143, grad norm: 0.0170229\n",
      "test accuracy 0.9366\n",
      "iter 7600, epoch 6, training accuracy 0.92, g: 0.690909\n",
      "weight norm: 0.0682159, grad norm: 0.0169091\n",
      "test accuracy 0.9374\n",
      "iter 7700, epoch 7, training accuracy 0.98, g: 0.7\n",
      "weight norm: 0.0681877, grad norm: 0.0155322\n",
      "test accuracy 0.9376\n",
      "iter 7800, epoch 7, training accuracy 0.94, g: 0.709091\n",
      "weight norm: 0.068093, grad norm: 0.0231573\n",
      "test accuracy 0.9384\n",
      "iter 7900, epoch 7, training accuracy 0.98, g: 0.718182\n",
      "weight norm: 0.0680011, grad norm: 0.0184886\n",
      "test accuracy 0.937\n",
      "iter 8000, epoch 7, training accuracy 0.94, g: 0.727273\n",
      "weight norm: 0.0679337, grad norm: 0.0430703\n",
      "test accuracy 0.9375\n",
      "iter 8100, epoch 7, training accuracy 0.94, g: 0.736364\n",
      "weight norm: 0.0677837, grad norm: 0.037864\n",
      "test accuracy 0.9372\n",
      "iter 8200, epoch 7, training accuracy 0.94, g: 0.745455\n",
      "weight norm: 0.0677068, grad norm: 0.0408942\n",
      "test accuracy 0.9378\n",
      "iter 8300, epoch 7, training accuracy 0.88, g: 0.754545\n",
      "weight norm: 0.0676274, grad norm: 0.0559758\n",
      "test accuracy 0.938\n",
      "iter 8400, epoch 7, training accuracy 0.96, g: 0.763636\n",
      "weight norm: 0.0674761, grad norm: 0.0229646\n",
      "test accuracy 0.9384\n",
      "iter 8500, epoch 7, training accuracy 0.92, g: 0.772727\n",
      "weight norm: 0.067462, grad norm: 0.0348962\n",
      "test accuracy 0.9391\n",
      "iter 8600, epoch 7, training accuracy 0.96, g: 0.781818\n",
      "weight norm: 0.0673909, grad norm: 0.0253576\n",
      "test accuracy 0.9392\n",
      "iter 8700, epoch 7, training accuracy 1, g: 0.790909\n",
      "weight norm: 0.0672299, grad norm: 0.0265897\n",
      "test accuracy 0.9383\n",
      "iter 8800, epoch 8, training accuracy 0.94, g: 0.8\n",
      "weight norm: 0.0671958, grad norm: 0.0338973\n",
      "test accuracy 0.9381\n",
      "iter 8900, epoch 8, training accuracy 0.9, g: 0.809091\n",
      "weight norm: 0.0671457, grad norm: 0.0589869\n",
      "test accuracy 0.9382\n",
      "iter 9000, epoch 8, training accuracy 0.96, g: 0.818182\n",
      "weight norm: 0.0670465, grad norm: 0.0268433\n",
      "test accuracy 0.9385\n",
      "iter 9100, epoch 8, training accuracy 0.92, g: 0.827273\n",
      "weight norm: 0.066923, grad norm: 0.0482812\n",
      "test accuracy 0.9399\n",
      "iter 9200, epoch 8, training accuracy 0.92, g: 0.836364\n",
      "weight norm: 0.0668562, grad norm: 0.0446689\n",
      "test accuracy 0.9403\n",
      "iter 9300, epoch 8, training accuracy 0.86, g: 0.845455\n",
      "weight norm: 0.066765, grad norm: 0.058707\n",
      "test accuracy 0.9402\n",
      "iter 9400, epoch 8, training accuracy 0.92, g: 0.854545\n",
      "weight norm: 0.0666817, grad norm: 0.0353211\n",
      "test accuracy 0.9407\n",
      "iter 9500, epoch 8, training accuracy 1, g: 0.863636\n",
      "weight norm: 0.0666551, grad norm: 0.0144326\n",
      "test accuracy 0.9398\n",
      "iter 9600, epoch 8, training accuracy 1, g: 0.872727\n",
      "weight norm: 0.0664834, grad norm: 0.022034\n",
      "test accuracy 0.9403\n",
      "iter 9700, epoch 8, training accuracy 0.84, g: 0.881818\n",
      "weight norm: 0.0664206, grad norm: 0.0664076\n",
      "test accuracy 0.9397\n",
      "iter 9800, epoch 8, training accuracy 0.94, g: 0.890909\n",
      "weight norm: 0.0664255, grad norm: 0.0179294\n",
      "test accuracy 0.9388\n",
      "iter 9900, epoch 9, training accuracy 0.88, g: 0.9\n",
      "weight norm: 0.0662825, grad norm: 0.0527151\n",
      "test accuracy 0.9392\n",
      "iter 10000, epoch 9, training accuracy 0.96, g: 0.909091\n",
      "weight norm: 0.0663148, grad norm: 0.0183966\n",
      "test accuracy 0.9393\n",
      "iter 10100, epoch 9, training accuracy 0.96, g: 0.918182\n",
      "weight norm: 0.0662001, grad norm: 0.0187677\n",
      "test accuracy 0.9384\n",
      "iter 10200, epoch 9, training accuracy 1, g: 0.927273\n",
      "weight norm: 0.066127, grad norm: 0.0239425\n",
      "test accuracy 0.9359\n",
      "iter 10300, epoch 9, training accuracy 0.98, g: 0.936364\n",
      "weight norm: 0.0661014, grad norm: 0.0157192\n",
      "test accuracy 0.9377\n",
      "iter 10400, epoch 9, training accuracy 0.96, g: 0.945455\n",
      "weight norm: 0.0660321, grad norm: 0.0329156\n",
      "test accuracy 0.9378\n",
      "iter 10500, epoch 9, training accuracy 0.94, g: 0.954545\n",
      "weight norm: 0.0659871, grad norm: 0.0238099\n",
      "test accuracy 0.9378\n",
      "iter 10600, epoch 9, training accuracy 0.96, g: 0.963636\n",
      "weight norm: 0.0659287, grad norm: 0.049893\n",
      "test accuracy 0.9381\n",
      "iter 10700, epoch 9, training accuracy 1, g: 0.972727\n",
      "weight norm: 0.0658608, grad norm: 0.0290842\n",
      "test accuracy 0.9385\n",
      "iter 10800, epoch 9, training accuracy 0.88, g: 0.981818\n",
      "weight norm: 0.0658216, grad norm: 0.0945168\n",
      "test accuracy 0.9396\n",
      "iter 10900, epoch 9, training accuracy 0.88, g: 0.990909\n",
      "weight norm: 0.0657658, grad norm: 0.0583897\n",
      "test accuracy 0.9392\n",
      "iter 11000, epoch 10, training accuracy 0.94, g: 1\n",
      "weight norm: 0.0657078, grad norm: 0.0132563\n",
      "test accuracy 0.9369\n",
      "iter 11100, epoch 10, training accuracy 0.94, g: 1\n",
      "weight norm: 0.0656363, grad norm: 0.0267587\n",
      "test accuracy 0.9378\n",
      "iter 11200, epoch 10, training accuracy 0.94, g: 1\n",
      "weight norm: 0.0655501, grad norm: 0.0356448\n",
      "test accuracy 0.9368\n",
      "iter 11300, epoch 10, training accuracy 0.9, g: 1\n",
      "weight norm: 0.065532, grad norm: 0.0709176\n",
      "test accuracy 0.938\n",
      "iter 11400, epoch 10, training accuracy 0.98, g: 1\n",
      "weight norm: 0.0655117, grad norm: 0.0155149\n",
      "test accuracy 0.9383\n",
      "iter 11500, epoch 10, training accuracy 0.94, g: 1\n",
      "weight norm: 0.0654491, grad norm: 0.0208448\n",
      "test accuracy 0.9384\n",
      "iter 11600, epoch 10, training accuracy 0.92, g: 1\n",
      "weight norm: 0.0653561, grad norm: 0.0268754\n",
      "test accuracy 0.9381\n",
      "iter 11700, epoch 10, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0653679, grad norm: 0.0326958\n",
      "test accuracy 0.939\n",
      "iter 11800, epoch 10, training accuracy 0.98, g: 1\n",
      "weight norm: 0.0653132, grad norm: 0.0101036\n",
      "test accuracy 0.9396\n",
      "iter 11900, epoch 10, training accuracy 0.88, g: 1\n",
      "weight norm: 0.0652385, grad norm: 0.0323189\n",
      "test accuracy 0.9391\n",
      "iter 12000, epoch 10, training accuracy 0.94, g: 1\n",
      "weight norm: 0.0652092, grad norm: 0.0217616\n",
      "test accuracy 0.9382\n",
      "iter 12100, epoch 11, training accuracy 0.96, g: 1\n",
      "weight norm: 0.065151, grad norm: 0.015813\n",
      "test accuracy 0.9397\n",
      "iter 12200, epoch 11, training accuracy 0.9, g: 1\n",
      "weight norm: 0.0650894, grad norm: 0.0801962\n",
      "test accuracy 0.9384\n",
      "iter 12300, epoch 11, training accuracy 0.94, g: 1\n",
      "weight norm: 0.0650682, grad norm: 0.0320349\n",
      "test accuracy 0.9385\n",
      "iter 12400, epoch 11, training accuracy 0.92, g: 1\n",
      "weight norm: 0.0650244, grad norm: 0.0350995\n",
      "test accuracy 0.9393\n",
      "iter 12500, epoch 11, training accuracy 0.92, g: 1\n",
      "weight norm: 0.064969, grad norm: 0.0345752\n",
      "test accuracy 0.939\n",
      "iter 12600, epoch 11, training accuracy 0.92, g: 1\n",
      "weight norm: 0.0649823, grad norm: 0.0290518\n",
      "test accuracy 0.937\n",
      "iter 12700, epoch 11, training accuracy 0.9, g: 1\n",
      "weight norm: 0.0649426, grad norm: 0.0249888\n",
      "test accuracy 0.9373\n",
      "iter 12800, epoch 11, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0648715, grad norm: 0.0849089\n",
      "test accuracy 0.9378\n",
      "iter 12900, epoch 11, training accuracy 0.88, g: 1\n",
      "weight norm: 0.0648083, grad norm: 0.0258094\n",
      "test accuracy 0.9381\n",
      "iter 13000, epoch 11, training accuracy 0.98, g: 1\n",
      "weight norm: 0.0648282, grad norm: 0.0448299\n",
      "test accuracy 0.9382\n",
      "iter 13100, epoch 11, training accuracy 0.86, g: 1\n",
      "weight norm: 0.0647872, grad norm: 0.0828608\n",
      "test accuracy 0.9384\n",
      "iter 13200, epoch 12, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0647598, grad norm: 0.0242094\n",
      "test accuracy 0.9381\n",
      "iter 13300, epoch 12, training accuracy 0.94, g: 1\n",
      "weight norm: 0.0647182, grad norm: 0.0611372\n",
      "test accuracy 0.9382\n",
      "iter 13400, epoch 12, training accuracy 1, g: 1\n",
      "weight norm: 0.0646969, grad norm: 0.0290295\n",
      "test accuracy 0.9385\n",
      "iter 13500, epoch 12, training accuracy 0.92, g: 1\n",
      "weight norm: 0.0646648, grad norm: 0.0432645\n",
      "test accuracy 0.9384\n",
      "iter 13600, epoch 12, training accuracy 0.98, g: 1\n",
      "weight norm: 0.0646325, grad norm: 0.0207885\n",
      "test accuracy 0.9386\n",
      "iter 13700, epoch 12, training accuracy 0.98, g: 1\n",
      "weight norm: 0.0645716, grad norm: 0.0328549\n",
      "test accuracy 0.9389\n",
      "iter 13800, epoch 12, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0645662, grad norm: 0.0279141\n",
      "test accuracy 0.9394\n",
      "iter 13900, epoch 12, training accuracy 0.94, g: 1\n",
      "weight norm: 0.0645068, grad norm: 0.0298902\n",
      "test accuracy 0.9393\n",
      "iter 14000, epoch 12, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0644816, grad norm: 0.037089\n",
      "test accuracy 0.9396\n",
      "iter 14100, epoch 12, training accuracy 0.9, g: 1\n",
      "weight norm: 0.0644504, grad norm: 0.0303093\n",
      "test accuracy 0.939\n",
      "iter 14200, epoch 12, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0644112, grad norm: 0.0244112\n",
      "test accuracy 0.9394\n",
      "iter 14300, epoch 13, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0644147, grad norm: 0.0183746\n",
      "test accuracy 0.9394\n",
      "iter 14400, epoch 13, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0643794, grad norm: 0.125731\n",
      "test accuracy 0.9389\n",
      "iter 14500, epoch 13, training accuracy 0.98, g: 1\n",
      "weight norm: 0.0643633, grad norm: 0.0221044\n",
      "test accuracy 0.939\n",
      "iter 14600, epoch 13, training accuracy 1, g: 1\n",
      "weight norm: 0.0643269, grad norm: 0.0194525\n",
      "test accuracy 0.9392\n",
      "iter 14700, epoch 13, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0643064, grad norm: 0.0422388\n",
      "test accuracy 0.9391\n",
      "iter 14800, epoch 13, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0642393, grad norm: 0.0365853\n",
      "test accuracy 0.9389\n",
      "iter 14900, epoch 13, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0642328, grad norm: 0.0371157\n",
      "test accuracy 0.9381\n",
      "iter 15000, epoch 13, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0642177, grad norm: 0.0479524\n",
      "test accuracy 0.938\n",
      "iter 15100, epoch 13, training accuracy 1, g: 1\n",
      "weight norm: 0.0641844, grad norm: 0.0240725\n",
      "test accuracy 0.9388\n",
      "iter 15200, epoch 13, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0641807, grad norm: 0.0287757\n",
      "test accuracy 0.9385\n",
      "iter 15300, epoch 13, training accuracy 0.9, g: 1\n",
      "weight norm: 0.064162, grad norm: 0.055044\n",
      "test accuracy 0.9387\n",
      "iter 15400, epoch 14, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0641492, grad norm: 0.0150086\n",
      "test accuracy 0.9393\n",
      "iter 15500, epoch 14, training accuracy 0.92, g: 1\n",
      "weight norm: 0.0641156, grad norm: 0.0316092\n",
      "test accuracy 0.9391\n",
      "iter 15600, epoch 14, training accuracy 0.98, g: 1\n",
      "weight norm: 0.0640808, grad norm: 0.0321994\n",
      "test accuracy 0.9399\n",
      "iter 15700, epoch 14, training accuracy 1, g: 1\n",
      "weight norm: 0.0640536, grad norm: 0.0365559\n",
      "test accuracy 0.9394\n",
      "iter 15800, epoch 14, training accuracy 0.86, g: 1\n",
      "weight norm: 0.0640648, grad norm: 0.0668526\n",
      "test accuracy 0.9395\n",
      "iter 15900, epoch 14, training accuracy 1, g: 1\n",
      "weight norm: 0.0640059, grad norm: 0.0182609\n",
      "test accuracy 0.9401\n",
      "iter 16000, epoch 14, training accuracy 0.98, g: 1\n",
      "weight norm: 0.0639949, grad norm: 0.020816\n",
      "test accuracy 0.9399\n",
      "iter 16100, epoch 14, training accuracy 0.94, g: 1\n",
      "weight norm: 0.0639613, grad norm: 0.0259849\n",
      "test accuracy 0.9403\n",
      "iter 16200, epoch 14, training accuracy 0.92, g: 1\n",
      "weight norm: 0.0639546, grad norm: 0.0825904\n",
      "test accuracy 0.94\n",
      "iter 16300, epoch 14, training accuracy 0.92, g: 1\n",
      "weight norm: 0.0639312, grad norm: 0.0644607\n",
      "test accuracy 0.9403\n",
      "iter 16400, epoch 14, training accuracy 0.92, g: 1\n",
      "weight norm: 0.0639071, grad norm: 0.0239107\n",
      "test accuracy 0.9402\n",
      "iter 16500, epoch 15, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0639064, grad norm: 0.0230419\n",
      "test accuracy 0.9407\n",
      "iter 16600, epoch 15, training accuracy 0.98, g: 1\n",
      "weight norm: 0.0638802, grad norm: 0.0160905\n",
      "test accuracy 0.94\n",
      "iter 16700, epoch 15, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0638278, grad norm: 0.0263678\n",
      "test accuracy 0.9408\n",
      "iter 16800, epoch 15, training accuracy 0.94, g: 1\n",
      "weight norm: 0.0637861, grad norm: 0.0347499\n",
      "test accuracy 0.9403\n",
      "iter 16900, epoch 15, training accuracy 1, g: 1\n",
      "weight norm: 0.063788, grad norm: 0.0304127\n",
      "test accuracy 0.9402\n",
      "iter 17000, epoch 15, training accuracy 0.88, g: 1\n",
      "weight norm: 0.0637884, grad norm: 0.113026\n",
      "test accuracy 0.9409\n",
      "iter 17100, epoch 15, training accuracy 0.94, g: 1\n",
      "weight norm: 0.0637632, grad norm: 0.0962916\n",
      "test accuracy 0.9403\n",
      "iter 17200, epoch 15, training accuracy 0.98, g: 1\n",
      "weight norm: 0.0637446, grad norm: 0.0212116\n",
      "test accuracy 0.9403\n",
      "iter 17300, epoch 15, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0637199, grad norm: 0.0410603\n",
      "test accuracy 0.9406\n",
      "iter 17400, epoch 15, training accuracy 0.9, g: 1\n",
      "weight norm: 0.0637053, grad norm: 0.0446579\n",
      "test accuracy 0.9403\n",
      "iter 17500, epoch 15, training accuracy 0.88, g: 1\n",
      "weight norm: 0.0636936, grad norm: 0.075385\n",
      "test accuracy 0.9402\n",
      "iter 17600, epoch 16, training accuracy 0.98, g: 1\n",
      "weight norm: 0.0636607, grad norm: 0.035583\n",
      "test accuracy 0.9402\n",
      "iter 17700, epoch 16, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0636293, grad norm: 0.0357885\n",
      "test accuracy 0.9401\n",
      "iter 17800, epoch 16, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0636202, grad norm: 0.0285449\n",
      "test accuracy 0.9404\n",
      "iter 17900, epoch 16, training accuracy 0.98, g: 1\n",
      "weight norm: 0.063599, grad norm: 0.0339188\n",
      "test accuracy 0.9401\n",
      "iter 18000, epoch 16, training accuracy 0.94, g: 1\n",
      "weight norm: 0.0635769, grad norm: 0.0339635\n",
      "test accuracy 0.9404\n",
      "iter 18100, epoch 16, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0635636, grad norm: 0.0666758\n",
      "test accuracy 0.9402\n",
      "iter 18200, epoch 16, training accuracy 0.94, g: 1\n",
      "weight norm: 0.0635734, grad norm: 0.0613899\n",
      "test accuracy 0.9402\n",
      "iter 18300, epoch 16, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0635575, grad norm: 0.0878895\n",
      "test accuracy 0.9402\n",
      "iter 18400, epoch 16, training accuracy 0.94, g: 1\n",
      "weight norm: 0.0635251, grad norm: 0.0426467\n",
      "test accuracy 0.9402\n",
      "iter 18500, epoch 16, training accuracy 0.94, g: 1\n",
      "weight norm: 0.063508, grad norm: 0.0804624\n",
      "test accuracy 0.9402\n",
      "iter 18600, epoch 16, training accuracy 0.9, g: 1\n",
      "weight norm: 0.0635067, grad norm: 0.0822954\n",
      "test accuracy 0.9408\n",
      "iter 18700, epoch 17, training accuracy 0.98, g: 1\n",
      "weight norm: 0.0634723, grad norm: 0.0218864\n",
      "test accuracy 0.9406\n",
      "iter 18800, epoch 17, training accuracy 0.98, g: 1\n",
      "weight norm: 0.0634685, grad norm: 0.0274252\n",
      "test accuracy 0.9407\n",
      "iter 18900, epoch 17, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0634466, grad norm: 0.0370783\n",
      "test accuracy 0.9404\n",
      "iter 19000, epoch 17, training accuracy 0.94, g: 1\n",
      "weight norm: 0.0634361, grad norm: 0.0275279\n",
      "test accuracy 0.9406\n",
      "iter 19100, epoch 17, training accuracy 0.98, g: 1\n",
      "weight norm: 0.063405, grad norm: 0.0186011\n",
      "test accuracy 0.9407\n",
      "iter 19200, epoch 17, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0633849, grad norm: 0.0374741\n",
      "test accuracy 0.9409\n",
      "iter 19300, epoch 17, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0633849, grad norm: 0.0164327\n",
      "test accuracy 0.941\n",
      "iter 19400, epoch 17, training accuracy 0.98, g: 1\n",
      "weight norm: 0.0633756, grad norm: 0.0100884\n",
      "test accuracy 0.9415\n",
      "iter 19500, epoch 17, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0633578, grad norm: 0.0439337\n",
      "test accuracy 0.9416\n",
      "iter 19600, epoch 17, training accuracy 0.94, g: 1\n",
      "weight norm: 0.0633369, grad norm: 0.024323\n",
      "test accuracy 0.9414\n",
      "iter 19700, epoch 17, training accuracy 0.9, g: 1\n",
      "weight norm: 0.0633418, grad norm: 0.0504867\n",
      "test accuracy 0.9417\n",
      "iter 19800, epoch 18, training accuracy 0.94, g: 1\n",
      "weight norm: 0.063334, grad norm: 0.0216369\n",
      "test accuracy 0.9414\n",
      "iter 19900, epoch 18, training accuracy 0.88, g: 1\n",
      "weight norm: 0.0633052, grad norm: 0.0837064\n",
      "test accuracy 0.9415\n",
      "iter 20000, epoch 18, training accuracy 0.9, g: 1\n",
      "weight norm: 0.0632956, grad norm: 0.0527454\n",
      "test accuracy 0.9416\n",
      "iter 20100, epoch 18, training accuracy 1, g: 1\n",
      "weight norm: 0.0632855, grad norm: 0.01484\n",
      "test accuracy 0.9413\n",
      "iter 20200, epoch 18, training accuracy 1, g: 1\n",
      "weight norm: 0.0632791, grad norm: 0.0253223\n",
      "test accuracy 0.9416\n",
      "iter 20300, epoch 18, training accuracy 0.92, g: 1\n",
      "weight norm: 0.06326, grad norm: 0.0502903\n",
      "test accuracy 0.9415\n",
      "iter 20400, epoch 18, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0632467, grad norm: 0.0246441\n",
      "test accuracy 0.9414\n",
      "iter 20500, epoch 18, training accuracy 0.98, g: 1\n",
      "weight norm: 0.0632339, grad norm: 0.0173267\n",
      "test accuracy 0.9413\n",
      "iter 20600, epoch 18, training accuracy 1, g: 1\n",
      "weight norm: 0.0632152, grad norm: 0.0220793\n",
      "test accuracy 0.9414\n",
      "iter 20700, epoch 18, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0632139, grad norm: 0.0387736\n",
      "test accuracy 0.9416\n",
      "iter 20800, epoch 18, training accuracy 0.94, g: 1\n",
      "weight norm: 0.0632002, grad norm: 0.0316427\n",
      "test accuracy 0.9416\n",
      "iter 20900, epoch 19, training accuracy 0.94, g: 1\n",
      "weight norm: 0.0631916, grad norm: 0.0283289\n",
      "test accuracy 0.9419\n",
      "iter 21000, epoch 19, training accuracy 0.92, g: 1\n",
      "weight norm: 0.0631821, grad norm: 0.0393511\n",
      "test accuracy 0.9413\n",
      "iter 21100, epoch 19, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0631742, grad norm: 0.0231838\n",
      "test accuracy 0.9417\n",
      "iter 21200, epoch 19, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0631681, grad norm: 0.0307308\n",
      "test accuracy 0.9416\n",
      "iter 21300, epoch 19, training accuracy 0.94, g: 1\n",
      "weight norm: 0.0631512, grad norm: 0.0345956\n",
      "test accuracy 0.9418\n",
      "iter 21400, epoch 19, training accuracy 0.92, g: 1\n",
      "weight norm: 0.0631417, grad norm: 0.017636\n",
      "test accuracy 0.9417\n",
      "iter 21500, epoch 19, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0631283, grad norm: 0.0520179\n",
      "test accuracy 0.9417\n",
      "iter 21600, epoch 19, training accuracy 0.94, g: 1\n",
      "weight norm: 0.0631223, grad norm: 0.0591813\n",
      "test accuracy 0.9417\n",
      "iter 21700, epoch 19, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0631066, grad norm: 0.0271943\n",
      "test accuracy 0.9414\n",
      "iter 21800, epoch 19, training accuracy 0.96, g: 1\n",
      "weight norm: 0.0630994, grad norm: 0.0316797\n",
      "test accuracy 0.9414\n",
      "iter 21900, epoch 19, training accuracy 0.92, g: 1\n",
      "weight norm: 0.0630947, grad norm: 0.0579421\n",
      "test accuracy 0.9416\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_iter):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(mini_batch_size)\n",
    "\n",
    "  epoch = i / iter_per_epoch\n",
    "  gs = min(epoch / tau, 1.0)\n",
    "\n",
    "  if i % 100 == 0:\n",
    "    summary_str, train_accuracy, w_norm, grad_norm = sess.run([merged, accuracy, weight_norm, gradient_norm], feed_dict={\n",
    "        x: batch_xs,\n",
    "        y_: batch_ys,\n",
    "        g: gs,\n",
    "        keep_prob: 1.0,\n",
    "    })\n",
    "    writer.add_summary(summary_str, i)\n",
    "    print(\"iter %d, epoch %d, training accuracy %g, g: %g\" % (i, epoch, train_accuracy, gs))\n",
    "    print(\"weight norm: %g, grad norm: %g\" % (w_norm, grad_norm))\n",
    "    print(\"test accuracy %g\" % accuracy.eval(feed_dict={ x: mnist.test.images, y_: mnist.test.labels, g: gs , keep_prob: 1.0}))\n",
    "\n",
    "  train_step.run(feed_dict={ x: batch_xs, y_: batch_ys, g: gs, keep_prob: 0.95})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
